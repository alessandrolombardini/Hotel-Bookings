{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progetto: Hotel Booking\n",
    "\n",
    "**Programmazione di Applicazioni Data Intensive**  \n",
    "Laurea in Ingegneria e Scienze Informatiche  \n",
    "DISI - Università di Bologna, Cesena\n",
    "\n",
    "Studente: Alessandro Lombardini  \n",
    "alessandr.lombardin3@unibo.it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup librerie\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso di studio\n",
    "\n",
    "- Data una prenotazione presso un hotel effettuata da un cliente, si vuole classificare questa come cancellata o non cancellata\n",
    "- Di ciascuna prenotazione sono disponibili delle caratteristiche\n",
    "  - numero di adulti, richiesta di un parcheggio, tipo di pasto richiesto, ...\n",
    "- Vogliamo addestrare un modello a classificare ciascuna prenotazione sulla base di queste caratteristiche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilizziamo il [Hotel booking demand](https://www.kaggle.com/jessemostipak/hotel-booking-demand), in cui ogni osservazione contiene le caratteristiche di una prenotazione\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HBD_URL = \"https://bitbucket.org/alessandrolombardini/gender-recognition-by-voice/raw/31a37837e84ff9d65e9359a57042a4bc8f907c9c/hotel_bookings.csv\"\n",
    "hbd = pd.read_csv(HBD_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hbd.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Si tratta di classificazione binaria, ovvero con due possibili classi\n",
    "- La colonna `is_canceled` indica la classificazione delle prenotazioni \n",
    "    - 0 = non cancellata, 1 = cancellata\n",
    "- Le altre 31 colonne corrispondono alle altre variabili legate alla prenotazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Il dataset presenta:\n",
    "    - 119390 istanze \n",
    "    - 32 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hbd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lista delle variabili\n",
    "\n",
    "- hotel: hotel prenotato dall'ospite (H1 = Resort Hotel or H2 = City Hotel)\n",
    "- lead_time: numero di giorni previsti dal giorno di prenotazione al giorno di arrivo in hotel\n",
    "- arrival_date_year: anno di arrivo\n",
    "- arrival_date_month: mese di arrivo \n",
    "- arrival_date_week_number: numero della settimana dell'anno di arrivo \n",
    "- arrival_date_day_of_month: giorno del mese di arrivo\n",
    "- stays_in_weekend_nights: numero di notti del weekend (Sabato e Domenica) prenotate\n",
    "- stays_in_week_nights:  numero di notti non nel weekend (da Lunedi a Venerdi) prenotate\n",
    "- adults: numero di adulti \n",
    "- children: numero di bambini \n",
    "- babies: numero di neonati\n",
    "- meal: combinazione di pasti richiesti (Undefined/SC – no meal package; BB – Bed & Breakfast; HB – Half board (breakfast and one other meal – usually dinner); FB – Full board (breakfast, lunch and dinner))\n",
    "- country: stato di provenienza\n",
    "- market_segment: segmento di mercato di destinazione \n",
    "- distribution_channel: soggetto per tramite del quale la prenotazione è avvenuto (TA/TO: Travel Agents, Direct: il client, ed altri)\n",
    "- is_repeated_guest: indica se la prenotazione è fatta da un cliente che aveva già prenotato in passato\n",
    "    - 1: Si, aveva già prenotato\n",
    "    - 0: No, non aveva mai prenotato\n",
    "- previous_cancellations: numero di prenotazioni effettuate in passato dal clienti\n",
    "- previous_bookings_not_canceled: numero di prenotazioni effettuate in passato dal cliente e non cancellate\n",
    "- reserved_room_type: codice del tipo di stanza richiesta dal cliente\n",
    "- assigned_room_type: codice del tipo di stanza assegnata alla prenotazione. A volte vengono assegnate stanze diverse da quelle riservate per motivi legati all'Hotel (es. overbooking) o per richiesta del cliente. \n",
    "- booking_changes: numero di cambiamenti apportati alla prenotazione fino al momento del Check-In o della cancellazione\n",
    "- deposit_type: indica se il cliente ha effettuato un deposito per garantirsi la prenotazione\n",
    "    - No Deposit: nessun deposito è stato fatto\n",
    "    - Non Refund: è stato pagato l'intero importo del soggiorno\n",
    "    - Refundable: è stata pagata solo una parte dell'importo dell'intero soggiorno\n",
    "- agent: ID dell'agente di viaggio che ha effettuato la prenotazione\n",
    "- company: ID della compagnia che ha effettuato la prenotazione o che ha pagato la prenotazione. \n",
    "- days_in_waiting_list: numero di giorni in cui la prenotazione è rimasta in lista di attesa prima di essere confermata al cliente\n",
    "- customer_type: tipologia di prenotazione\n",
    "    - Contract: la prenotazione è associata ad un contratto\n",
    "    - Group: la prenotazione è associata ad un gruppo\n",
    "    - Transient: la prenostazione non è parte ne di un gruppo ne di un contratto, e non è associata ad altre prenotazione Transient \n",
    "    - Transient-party: la prenotazione è Transient ed è associata ad altre prenotazioni Transient\n",
    "- adr: Avarage Daily Rate, definito come il costo del soggiorno diviso il numero di notti\n",
    "- required_car_parking_spaces: numero di spazi macchina richiesti dal cliente\n",
    "- total_of_special_requests: numero di richieste speciali fatte dal cliente\n",
    "- reservation_status: ultimo stato registrato della prenotazione\n",
    "    - Canceled: la prenotazione è stata cancellata dal cliente\n",
    "    - Check-Out: il client ha effettuato il Check-In e la sua permanenza è terminata\n",
    "    - No-Show: il cliente non ha effettuato il Check-In e ha informato l'hotel del motivo\n",
    "- reservation_status_date: ultima data in cui la variabile reservation_status è stata modificara\n",
    "- **is_canceled: indica se la prenotazione è stata cancellata o no**\n",
    "    - 0: Non cancellata\n",
    "    - 1: Cancellata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La variabile **is_canceled** indica la classificazione della prenotazione, vogliamo stabilire il valore di questa variabile in funzione delle altre\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aumentiamo il limite di colonne che pandas di default ci consente di visualizzare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Il nostro obiettivo è realizzare un modello di classificazione per una specificia struttura ospitante, in questo caso l'hotel 'City Hotel'\n",
    "\n",
    "- Il dataset prevede istanze di più hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd[\"hotel\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vengono quindi rimosse le istanze dei restanti hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd = hbd[hbd.hotel == \"City Hotel\"]\n",
    "hbd[\"hotel\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Il dataset ora presenta:\n",
    "    - 79330 istanze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualizziamo le statistiche principali (media, dev, standard, ...) delle variabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I valori non presentano la stessa scala, la standardizzazione potrà quindi essere certamente utile.\n",
    "\n",
    "- Visualizziamo il numero di valori distinti per ciascuna feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La variabile `hotel` è ora completamente inutile, la elimino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd.drop(inplace=True, axis=1, labels=['hotel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La data, per come è espressa attualmente, non è ottimale. Conviene estrarre dei campi dalle date che si preveda abbiano particolare correlazione con ciò che si sta prevedendo\n",
    "\n",
    "- Abbiamo:\n",
    "    - arrival_date_year \n",
    "    - arrival_date_month \n",
    "    - arrival_date_week_number\n",
    "    - arrival_date_day_of_month\n",
    "    \n",
    "- Vogliamo ottenere il nome del giorno di arrivo, che risulta essere più rilevante del numero del giorno in se\n",
    "    - Converto la variabile arrival_date_month da stringa (ovvero il nome del mese) ad intero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "dict_month_convertion = dict((v,k) for k,v in enumerate(calendar.month_name))\n",
    "hbd[\"arrival_date_month\"] = hbd[\"arrival_date_month\"].map(dict_month_convertion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd[\"arrival_date_month\"].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ora possiamo ottenere la nuova variabile `arrival_date_day`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "import calendar \n",
    "  \n",
    "def findDay(date): \n",
    "    day = datetime.datetime.strptime(date, '%d %m %Y').weekday() \n",
    "    return (calendar.day_name[day]) \n",
    "\n",
    "arrival_date_day = []\n",
    "for index, row in hbd.iterrows():\n",
    "    arrival_date_day.append(findDay(\"{0} {1} {2}\".format(row[\"arrival_date_day_of_month\"], row[\"arrival_date_month\"], row[\"arrival_date_year\"])))\n",
    "\n",
    "hbd.insert(2, \"arrival_date_day\", arrival_date_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd[\"arrival_date_day\"].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Possiamo eliminare la variabile `arrival_date_day_of_month`\n",
    "- Eliminiamo anche la variabile `arrival_date_year`, in quanto scarsamente variabile e inutile (se non controproducente) per effettuare delle previsioni  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd.drop(inplace=True, axis=1, labels=['arrival_date_year', 'arrival_date_day_of_month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La variabile `assigned_room_type`, cercando di intuirne il significato, potrebbe non essere disponibile al momento della prenotazione, ma solo al momento del Check-In. E' dunque da rimuovere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd.drop(inplace=True, axis=1, labels=['assigned_room_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Osservando la descrizione delle variabili è possibile notare come vi sia una grossa dipendenza tra le variabili `is_canceled` e `reservation_status`\n",
    "\n",
    "- I possibili valori di `reservation_status` sono:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd[\"reservation_status\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Il valore 'Check-Out' potrebbe corrispondere alla mancata cancellazione, mentre il valore 'Canceled' alla effettiva cancellazione. Anche il campo 'No-Show' potrebbe essere considerato come prenotazione cancellata.\n",
    "\n",
    "- Contiamo le istanze dei possibili valori di `reservation_status`, al fine di determinare se la variabile è identica alla variabile is_canceled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd[\"reservation_status\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Contiamo ora, per ciascun valore di `reservation_status`, quante prenotazioni sono state cancellate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd.groupby(['reservation_status']).sum()[\"is_canceled\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notiamo subito che la considerazione è corretta, le variabili `is_canceled` e `reservation_status` coincidono.\n",
    "    - Il valore Check-Out viene utilizzato quando la prenotazione non è stata cancellata\n",
    "    - I valori 'Canceled' e 'No-Shown' definisco entrambi una situazione in cui la prenotazione è stata cancellata.\n",
    "\n",
    "\n",
    "- Questa variabile va dunque rimossa, e con essa `reservation_status_date`, in quanto inutile senza `reservation_status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd.drop(inplace=True, axis=1, labels=['reservation_status', 'reservation_status_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Riassumiamo le variabili e i loro tipi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Verifico la presenza del valore `nan` nelle istanze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Noto la presenza di valori nulli nelle variabili: \n",
    "    - `children` \n",
    "    - `country`\n",
    "    - `agent`\n",
    "    - `company`\n",
    "    \n",
    "    \n",
    "- Per le variabili `children` e `country` il valore nullo non è accettabile, per cui rimuovo quelle istanze "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd.dropna(subset=[\"country\", \"children\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converto la variabile children da float ad intero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd[\"children\"] = hbd[\"children\"].astype(\"int64\")\n",
    "hbd[\"children\"].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La variabile `company` è nulla in quasi tutte le istanze, mentre `agent` per una buona parte di esse. \n",
    "\n",
    "- Il valore nullo in questo caso è però di nostro interesse, in quanto implica che per quella prenotazione non è presente ne un agent ne una company\n",
    "    - Memorizzo, invece dell'identificativo presente all'interno di questi campi, se il valore è nullo o no\n",
    "    - In questo modo sono comunque a conoscenza se la prenotazione è avvenuta per tramite di un agent e/o di una company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd.loc[hbd[\"agent\"].isnull(), \"agent\"] = 0 \n",
    "hbd.loc[hbd[\"agent\"] != 0, \"agent\"] = 1\n",
    "hbd.loc[hbd[\"company\"].isnull(), \"company\"] = 0 \n",
    "hbd.loc[hbd[\"company\"] != 0, \"company\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converto le due variabili ad intero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd[\"agent\"] = hbd[\"agent\"].astype(\"int64\")\n",
    "hbd[\"company\"] = hbd[\"company\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualizziamo la correlazione tra le coppie di features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hbd.corr().style.background_gradient(cmap='Spectral').set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisi esplorativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variabile `is_canceled`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stampiamo il numero di valori `Y` e `N` della variabile `is_canceled`, e rappresentiamo la distribuzione di tali valori in un diagramma a torta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd[\"is_canceled\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd[\"is_canceled\"].value_counts().plot.pie();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La suddivisione delle istanze nelle classi è abbastanza bilanciata, non siamo dunque soggetti ai problemi che un forte sblinciamento comporterebbe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In un problema di classificazione, è utile visualizzare quanto le variabili predittive siano correlate con la classe da predire\n",
    "\n",
    "- Vengono quindi ora mostrati sia grafici con la distribuzione delle variabili, ignorando la classe di appartenenza, sia grafici in cui  integriamo la classe di appertenenza, per valutare quanto le variabili siano utili nella predizione della classe. Questo ci consentirà di avere una visione completa sul contesto analizzato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variabile `lead_time`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analizziamo la variabile `lead_time`\n",
    "\n",
    "- Visualizziamo un'istogramma di `lead_time`, in cui in ogni intervallo si vede il numero di prenotazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(hbd[\"lead_time\"], 10).value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Le prenotazioni più frequenti sono quelle a breve termine, ovvero senza lunghi periodi fra il momento della prenotazione e l'arrivo in hotel\n",
    "\n",
    "- Visualizziamo un altro istogramma di `lead_time`, in cui in ogni intervallo si vede il numero di cancellazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd.groupby(pd.cut(hbd[\"lead_time\"], 10)).sum()[\"is_canceled\"].plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L'andamento è il medesimo, abbiamo più cancellazioni nelle prenotazioni a breve termine\n",
    "\n",
    "- Visualizziamo altri due istogrammi di `lead_time`:\n",
    "    - uno in cui per ogni intervallo abbiamo il numero totale di cancellazioni in quella fascia diviso il numero totale di prenotazioni sempre in quella fascia\n",
    "    - un altro, di tipo stacked, in cui in ogni intervallo si vede la suddivisione dei valori tra le classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(hbd.groupby(pd.cut(hbd[\"lead_time\"], 10)).sum()[\"is_canceled\"] / pd.cut(hbd[\"lead_time\"], 10).value_counts()).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd.pivot(columns=\"is_canceled\")[\"lead_time\"].plot.hist(bins=20, stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entrambi i grafici evidenziano che il tasso di cancellazione cresce al crescere del `lead_time`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variabile `country`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analizziamo la variabile `country`\n",
    "\n",
    "- Visualizziamo un'istogramma di `country`, in cui in venga visualizzato il tasso di cancellazione per ciascuno stato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancellation_by_state = hbd.groupby(['country']).sum()[\"is_canceled\"]\n",
    "reservation_by_state = hbd.groupby(['country']).count()[\"is_canceled\"]\n",
    "ratio_cancellation_by_state = (cancellation_by_state/reservation_by_state).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_cancellation_by_state.plot.bar(figsize=(16,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualizziamo un istogramma di `country`, in cui in venga visualizzato per ciascuno stato il numero totale di prenotazioni effettuate\n",
    "- Viene utilizzata la scala logaritmica per apprezzare meglio le differenze fra i vari stati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reservation_by_state.loc[ratio_cancellation_by_state.index].plot.bar(figsize=(16,4), log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualizziamo un ultimo istogramma di `country`, in cui in venga visualizzato per ciascuno stato il numero totale di cancellazioni effettuate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancellation_by_state.loc[ratio_cancellation_by_state.index].plot.bar(figsize=(16,4), log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I grafici evidenziano che il tasso di cancellazione è più alto per alcuni stati piuttosto che altri\n",
    "    - Alcuni stati presentano un tasso di cancellazione pari ad 1, ovvero tutte le prenotazioni sono state cancellate\n",
    "    - Alcuni stati presentano un tasso di cancellazione pari a 0, ovvero nessuna prenotazione è stata cancellata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variabile `deposit_type`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analizziamo la variabile `deposit_type`\n",
    "\n",
    "- Visualizziamo un'istogramma di `deposit_type`, in cui in per ogni possibile valore si vede il numero di prenotazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd[\"deposit_type\"].value_counts().plot.bar(log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualizziamo un'istogramma di `deposit_type`, in cui in per ogni possibile valore si vede il numero di cancellazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd.groupby(\"deposit_type\").sum()[\"is_canceled\"].plot.bar(log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualizziamo un ultimo istogramma di `deposit_type`, in cui in venga visualizzata per ciascuna possibile valore il tasso di cancellazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(hbd.groupby(\"deposit_type\").sum()[\"is_canceled\"] / hbd[\"deposit_type\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(hbd.groupby(\"deposit_type\").sum()[\"is_canceled\"] / hbd[\"deposit_type\"].value_counts()).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Il grafico evidenzia che per il valore 'Non Refund' la percentuale di cancellazioni è pari quasi al 100%\n",
    "\n",
    "- E' un po controintuitivo, per cui verifichiamo le istanze per averne certezza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd[hbd[\"deposit_type\"] == \"Non Refund\"][\"is_canceled\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Effettivamente pare che quasi tutte siano state cancellate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variabili `arrival_date_day`, `arrival_date_month`, `arrival_date_week_number` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 3, 1)\n",
    "(hbd.groupby(\"arrival_date_day\").sum()[\"is_canceled\"] / hbd[\"arrival_date_day\"].value_counts()).plot.bar(figsize=(16,4))\n",
    "plt.subplot(1, 3, 2)\n",
    "(hbd.groupby(\"arrival_date_month\").sum()[\"is_canceled\"] / hbd[\"arrival_date_month\"].value_counts()).plot.bar(figsize=(16,4))\n",
    "plt.subplot(1, 3, 3)\n",
    "(hbd.groupby(\"arrival_date_week_number\").sum()[\"is_canceled\"] / hbd[\"arrival_date_week_number\"].value_counts()).plot.bar(figsize=(16,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variabili `stays_in_weekend_nights`, `stays_in_week_nights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "(hbd.groupby(\"stays_in_weekend_nights\").sum()[\"is_canceled\"] / hbd[\"stays_in_weekend_nights\"].value_counts()).plot.bar(figsize=(16,4))\n",
    "plt.subplot(1, 2, 2)\n",
    "(hbd.groupby(\"stays_in_week_nights\").sum()[\"is_canceled\"] / hbd[\"stays_in_week_nights\"].value_counts()).plot.bar(figsize=(16,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variabile `agent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(hbd.groupby(\"agent\").sum()[\"is_canceled\"] / hbd[\"agent\"].value_counts()).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variabile `company`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(hbd.groupby(\"company\").sum()[\"is_canceled\"] / hbd[\"company\"].value_counts()).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variabile `distribution_channel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(hbd.groupby(\"distribution_channel\").sum()[\"is_canceled\"] / hbd[\"distribution_channel\"].value_counts()).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variabile `market_segment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(hbd.groupby(\"market_segment\").sum()[\"is_canceled\"] / hbd[\"market_segment\"].value_counts()).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variabile `booking_changes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(hbd.groupby(\"booking_changes\").sum()[\"is_canceled\"] / hbd[\"booking_changes\"].value_counts()).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variabile `meal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(hbd.groupby(\"meal\").sum()[\"is_canceled\"] / hbd[\"meal\"].value_counts()).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificazione lineare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convertiamo, per maggiore chiarezza, i valori della variabile `is_canceled` (ovvero 0 e 1) in `N` e `Y`:\n",
    "    - `0` diventa `N`, ovvero non cancellata\n",
    "    - `1` diventa `Y`, ovvero cancellata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbd[\"is_canceled\"] = hbd[\"is_canceled\"].map(lambda value: \"N\" if value is 0 else \"Y\")\n",
    "hbd[\"is_canceled\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Impostiamo come variabile da predire la classe `is_canceled` e come variabili predittive tutte le altre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hbd[\"is_canceled\"]\n",
    "X = hbd.drop(columns=\"is_canceled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Molte variabili sono categoriche, è quindi necessario applicare la binarizzazione delle feature, ovvero convertire ciascuna di esse in più variabili binarie. \n",
    "\n",
    "- Le variabili da convertire sono:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes[hbd.dtypes == np.object]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La conversione viene eseguita, in modo molto basilare, dal comando `get_dummies`\n",
    "    - NB: non sono previste features per tutti quei valori non presenti nel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Suddividiamo i dati in un training set e in un validation set con la funzione `train_test_split` con proporzione 66-33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=1/3, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definiamo un modello di regressione logistica più semplice possibile, configurandone l'implementazione e il seed per la casualità\n",
    "  - gli altri parametri sono lasciati ai valori di default, ad es. la regolarizzazione applicata è L2 con C=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = LogisticRegression(solver=\"saga\", random_state=42)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Addestriamo il modello sui dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mostriamo le classi previste dal modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NB: Quando effettuiamo una predizione di probabilità otteniamo due valori ([a, b])\n",
    "    - Il primo valore (a) si riferisce alla probabilità di ottenere la classe `N`\n",
    "    - Il secondo valore (b) si riferisce alla probabilità di ottenere la classe `Y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X_val[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_val[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definiamo una funzione per ottenere tutte le informazioni più interessanti che ci possono essere utili per valutare il modello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Oltre all'accuratezza come percentuale di classificazioni corrette, esistono altri modi per valutare l'accuratezza di un classificatore\n",
    "    - precision e recall sono particolarmente utili in caso di sbilanciamento tra le classi, per cui l'accuratezza può non essere un indicatore affidabile\n",
    "- Confrontando le classi predette da un classificatore su un set di dati con quelle reali, possiamo ottenere una matrice di confusione\n",
    "- Otteniamo la matrice col metodo confusion_matrix, passando i vettori di classi reali e predette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def print_model_informations(model, X_val, y_val):\n",
    "    y_pred = model.predict(X_val)\n",
    "    print(\"Accuracy =\", model.score(X_val, y_val))\n",
    "    print(\"\\nPrecision (Y) =\", precision_score(y_val,y_pred, pos_label=\"Y\"))\n",
    "    print(\"Precision (N) =\", precision_score(y_val,y_pred, pos_label=\"N\"))\n",
    "    print(\"\\nRecall (Y) =\", recall_score(y_val,y_pred, pos_label=\"Y\"))\n",
    "    print(\"Recall (N) =\", recall_score(y_val,y_pred, pos_label=\"N\"))\n",
    "    print(\"\\nF1 Score (Y) =\", f1_score(y_val,y_pred, pos_label=\"Y\"))\n",
    "    print(\"F1 Score (N) =\", f1_score(y_val,y_pred, pos_label=\"N\"))\n",
    "    print(\"F1 Score =\", f1_score(y_val,y_pred, average=\"macro\"))\n",
    "    print(\"\\nMatrice di confusione:\")\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    print(pd.DataFrame(cm, index=model.classes_, columns=model.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calcoliamo le misure del nostro modello "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model_informations(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Per avere una valutazione più completa del modello ottento, possiamo metterlo a confronto con quello che accadrebbe prendendo decisioni casuali\n",
    "    - Generiamo un serie di decisioni casuali (`Y` o `N`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "randoms = pd.Series(np.random.choice([\"Y\", \"N\"], size=(y_val.index.shape[0],)), index = y_val.index) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calcoliamo l'accuratezza di questo modello randomico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_val == randoms).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Abbiamo ottenuto un modello che ci consente di intraprendere decisioni più accurate di come le faremmo casualmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regolarizzazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nella regressione logistica possiamo applicare le teniche di regolarizzazione\n",
    "    - In particolare vogliamo applicare la regolarizzazione L1 che permette di azzerare i pesi delle variabili meno significative\n",
    "    - Applichiamo una forte regolarizzazione al fine di annullare più valiabili possibili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = LogisticRegression(solver=\"saga\", random_state=42, penalty=\"l1\", C=0.01)  \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Andiamo a visualizzare i coefficienti che incido maggiormente sia positivamente che negativamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(model.coef_[0], index=X.columns).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(model.coef_[0], index=X.columns).sort_values(ascending=False).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Da questo risultato ho stabilito buona delle variabili su cui mi sono concentrato in fase di analisi esplorativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation su classificazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quello che vogliamo fare ora è applicare la GridSearch per trovare gli iperparametri migliori\n",
    " \n",
    "- Poichè il dataset è molto ampio e la variabili sono molte, la ricerca degli iperparametri ottimali risulta essere molto dispendiosa.\n",
    "\n",
    "- Riduciamo la dimensione del dataset in termini di: \n",
    "    - istanze\n",
    "    - variabili \n",
    "        - Ottenuti i pesi della regolarizzazione L1, poniamo una soglia del +- 0.1 affinchè un coefficiente possa essere tenuto in considerazione. Se inferiore rimuoviamo quella variabile dal dataframe. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rimuoviamo buona parte delle istanze dal dateset di training\n",
    "    - Il dataset di evaluation lo lasciamo uguale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_v2, X_val_v2, y_train_v2, y_val_v2 = train_test_split(\n",
    "    X, y, \n",
    "    train_size=1/20,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_v2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rimuoviamo parte delle variabili, quelle meno significative, sia dal dataset di training che di evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = pd.Series(model.coef_[0], index=X.columns)\n",
    "coeff = coeff[(coeff < 0.1) & (coeff > -0.1)]\n",
    "X_train_v2.drop(axis=1,columns=coeff.index, inplace=True)\n",
    "X_val_v2.drop(axis=1,columns=coeff.index, inplace=True)\n",
    "print(\"Ho scartato\", coeff.shape[0], \"variabili\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_v2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Applichiamo ora la GridSearch per ottenere gli iperparametri migliori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "skf = StratifiedKFold(3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVC\n",
    "mod = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\", LogisticRegression(solver=\"saga\", random_state=42))\n",
    "])\n",
    "grid = [\n",
    "    {\n",
    "        \"scaler\": [None, StandardScaler()],\n",
    "        \"lr__penalty\": [\"none\"]\n",
    "    },\n",
    "    {\n",
    "        \"scaler\": [None, StandardScaler()],\n",
    "        \"lr__penalty\": [\"l2\", \"l1\"],\n",
    "        \"lr__C\": np.logspace(-3, 3, 7)\n",
    "    },\n",
    "    {\n",
    "        \"scaler\": [None, StandardScaler()],\n",
    "        \"lr__penalty\": [\"elasticnet\"],\n",
    "        \"lr__C\": np.logspace(-3, 3, 7),\n",
    "        \"lr__l1_ratio\": [0.2, 0.5, 0.7]\n",
    "    }\n",
    "]\n",
    "gs = GridSearchCV(mod, grid, cv=skf)\n",
    "gs.fit(X_train_v2, y_train_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(gs.cv_results_)\n",
    "result.sort_values(by=\"rank_test_score\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Andiamo a visualizzare le misure del miglior modello ottenuto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model_informations(gs, X_val_v2, y_val_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Possiamo notare come molte istanze 'Cancellate' vengano classificate come 'Non cancellate'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valutazione dei modelli di classificazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Andiamo a prendere i parametri dei tre modelli testati che hanno ottenuto i valori \"rank_test_score\" più alti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Primo in classifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loc[0, 'params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Secondo in classifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loc[1, 'params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Terzo in classifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loc[3, 'params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dai parametri mostrati genero tre modelli, i tre modelli ipoteticamente migliori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "model_1 = copy.deepcopy(gs.best_estimator_.set_params(**result.loc[0, 'params']))\n",
    "model_2 = copy.deepcopy(gs.best_estimator_.set_params(**result.loc[1, 'params']))\n",
    "model_3 = copy.deepcopy(gs.best_estimator_.set_params(**result.loc[2, 'params']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.get_params(deep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.get_params(deep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.get_params(deep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inoltre teniamo in considerazione anche, per puro confronto, il primo modello ottenuto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params(deep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intervallo di confidenza sui modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definiamo una funzione `conf_interval` che calcoli gli estremi dell'intervallo di confidenza e restituisca una tupla con i due estremi, dove:\n",
    "  - $a$ è l'accuratezza del modello misurata sul validation set\n",
    "  - N è il numero di osservazioni nel validation set\n",
    "  - Z è il valore tale per cui l'area sottesa dalla densità di probabilità $\\varphi(x)$ della distribuzione normale standard tra -Z e Z sia il livello di confidenza 1-𝛼\n",
    "  \n",
    "- Poichè a noi interessa valutare i modelli con una condifidenza del 95%, possiamo ricavare dalle apposite tabelle di valori che, per 1-𝛼 = 0.95 (𝛼=0.05), Z = 1.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_interval(a, N, Z=1.96):\n",
    "    c = (2 * N * a + Z**2) / (2 * (N + Z**2))\n",
    "    d = Z * np.sqrt(Z**2 + 4*N*a - 4*N*a**2) / (2 * (N + Z**2))\n",
    "    return c - d, c + d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definisco ora una funzione `model_conf_interval` in modo che:\n",
    "  - prenda in input un modello addestrato `model`, un validation set `X, y` e un livello di confidenza `level` (default 0.95)\n",
    "  - restituisca l'intervallo di confidenza dell'accuratezza del modello, servendosi della funzione `conf_interval` sopra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_conf_interval(model, X, y, level=0.95):\n",
    "    a = model.score(X, y)\n",
    "    N = X.shape[0]\n",
    "    Z = norm.ppf((1 + level) / 2)\n",
    "    return conf_interval(a, N, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Usiamo la funzione `model_conf_interval` per calcolare l'intervallo di confidenza al 95% dell'accuratezza dei tre modelli ottenuti stimata sul validation set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conf_interval(model_1, X_val_v2, y_val_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conf_interval(model_2, X_val_v2, y_val_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conf_interval(model_3, X_val_v2, y_val_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confronto tra modelli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dati due modelli diversi, vogliamo poter valutare se l'accuratezza  𝑎1  misurata su uno sia significativamente migliore della  𝑎2  misurata sull'altro.\n",
    "\n",
    "- Implementiamo la funzione `diff_interval` in modo che\n",
    "  - prenda in input le accuratezze `a1` e `a2`, i numeri di osservazioni `N1` e `N2` e il coefficiente `Z`\n",
    "  - calcoli l'intervallo di confidenza della differenza tra due modelli secondo la formula sopra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_interval(a1, a2, N1, N2, Z):\n",
    "    d = abs(a1 - a2)\n",
    "    sd = np.sqrt(a1 * (1-a1) / N1 + a2 * (1-a2) / N2)\n",
    "    return d - Z * sd, d + Z * sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implementiamo la funzione `model_diff_interval` in modo che\n",
    "  - prenda in input due modelli `m1, m2`, un validation set `X, y` e un livello di confidenza `level` (default 0.95)\n",
    "  - restituisca l'intervallo di confidenza della differenza di accuratezza tra i due modelli, valutati entrambi sul validation set dato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_diff_interval(m1, m2, X, y, level=0.95):\n",
    "    a1 = m1.score(X, y)\n",
    "    a2 = m2.score(X, y)\n",
    "    N = len(X)\n",
    "    Z = norm.ppf((1 + level) / 2)\n",
    "    return diff_interval(a1, a2, N, N, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilizziamo `model_diff_interval` per calcolare l'intervallo al 95\\% della differenza di accurateza sul validation set tra i tre modelli ottenuti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_diff_interval(model_1, model_2, X_val_v2, y_val_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_diff_interval(model_2, model_3, X_val_v2, y_val_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_diff_interval(model_1, model_3, X_val_v2, y_val_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In nessuno dei tre casi abbiamo la certezza che un modello sia meglio dell'altro\n",
    "\n",
    "- Poichè l'intervallo ottenuto include lo zero (l'estremo inferiore è negativo), non abbiamo la certezza al 95\\% (o altro livello di confidenza) che il modello con accuratezza stimata maggiore sia effettivamente migliore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretazione della conoscenza appresa\n",
    "\n",
    "- Interpretiamo ora la conoscenza appresa attraverso l'analisi dei parametri appresi (coefficienti degli iperpiani)\n",
    "\n",
    "- Analizziamo quali feature sono più positivamente o negativamente correlate ed in che misura con la variabile da predire\n",
    "\n",
    "- Poichè dei tre migliori modelli ottenuti non abbiamo certezza che uno sia migliore degli altri, prendiamo il primo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualizziamo le classi possibili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La classe `0` rappresenta la classe positiva, ovvero la classe che si ottiene se la probabilità supera il 50%, viceversa per la classe `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.predict(X_val_v2[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.predict_proba(X_val_v2[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualizziamo prima di tutto l'intercetta di questo modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.named_steps[\"lr\"].intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La probabilità di partenza è molto vicina a 0 (ovvero la classe `N`)\n",
    "\n",
    "- Visualizziamo il resto dei coefficienti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(model_1.named_steps[\"lr\"].coef_[0], index=X_train_v2.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Le variabili che presentano una maggiore influenza sul risultato sono:\n",
    "    - lead_time (-): all'aumentare del valore di lead_time la probabilità che una prenotazione venga cancellata diminuisce\n",
    "    - arrival_date_year (+): \n",
    "    - adults\n",
    "    - country\n",
    "    - reserved_room_type\n",
    "    - assigned_room_type\n",
    "    - deposit_type\n",
    "    - adr\n",
    "    - require_car_parking_spaces\n",
    "\n",
    "- Interessante notare come, essendo utilizzata la regressione Lasso, alcuni parametri sono stati azzerati.\n",
    "    - Queste variabili sono state considerate dal modello come irrilevanti per la predizione, quindi le ha scartate\n",
    "    - Le variabili in questione sono:\n",
    "        - is_repeated_guest\n",
    "        - previous_cancellations\n",
    "        - previous_bookings_not_canceled\n",
    "    - Queste variabili non hanno alcun tipo di correlazione con la possibilità che una prenotazione venga o no cancellata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificazione con reti neurali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=5, batch_size=50, activation=\"relu\", random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_val_v2, y_val_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=7, batch_size=50, activation=\"relu\", random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
